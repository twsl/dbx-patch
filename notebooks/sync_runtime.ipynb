{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Sync Databricks Runtime Files\n",
    "\n",
    "This utility notebook helps sync Databricks runtime files to your workspace for reference.\n",
    "\n",
    "**⚠️ Important:** This notebook is only useful when running **inside a Databricks cluster** to extract runtime files for reference purposes.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The `databricks/` folder in this repository contains **reference files** from Databricks runtime. These files show what Databricks modifies in the Python import system, which this library patches.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Run the cell below when inside a Databricks cluster to create a zip archive of the runtime files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create zip archive of Databricks runtime files\n",
    "output_path = \"/Workspace/Users/<your-userid>/runtime\"\n",
    "runtime_source = \"/databricks/python_shell/lib/dbruntime\"\n",
    "\n",
    "if os.path.exists(runtime_source):\n",
    "    print(f\"Creating archive from: {runtime_source}\")\n",
    "    shutil.make_archive(output_path, \"zip\", runtime_source)\n",
    "    print(f\"✅ Archive created: {output_path}.zip\")\n",
    "    print(\"\\nDownload this file and extract to the databricks/ folder in the repository\")\n",
    "else:\n",
    "    print(\"❌ Not running in Databricks environment\")\n",
    "    print(f\"   Expected path not found: {runtime_source}\")\n",
    "    print(\"\\n⚠️  This notebook only works inside a Databricks cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## After Downloading\n",
    "\n",
    "1. Download the `runtime.zip` file from your workspace\n",
    "2. Extract it to the `databricks/python_shell/lib/dbruntime/` folder in this repository\n",
    "3. These files serve as reference material for understanding what gets patched\n",
    "\n",
    "## Notes\n",
    "\n",
    "- These files are **READ-ONLY reference material**\n",
    "- They show the **original Databricks implementation** before patches\n",
    "- **DO NOT modify** these files directly\n",
    "- See [Copilot Instructions](../.github/copilot-instructions.md) for more details\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
